# Text normalization

The fully working model is [on huggingface](https://huggingface.co/saarus72/russian_text_normalizer), and a [nice chat](https://huggingface.co/spaces/saarus72/russian-text-normalization) is on HF Space as well.

### Why

A pet project as the (only) [other solution](https://github.com/snakers4/russian_stt_text_normalization) does not seem to be maintainable by either owner or others. Some others do exist and are, like, *bad*.

> E.g. for input `Ñ ĞºÑƒĞ¿Ğ¸Ğ» iphone 10X Ğ·Ğ° 14990 Ñ€ÑƒĞ± Ğ±ĞµĞ· 3-x Ñ‡Ğ°ÑĞ¾Ğ² Ğ¿Ğ¾Ğ»Ğ´ĞµĞ½ÑŒ Ğ¸ Ñ‚.Ğ´.` output of
> * [russian_stt_text_normalization](https://github.com/snakers4/russian_stt_text_normalization) itself is `Ñ ĞºÑƒĞ¿Ğ¸Ğ» Ğ¸Ñ„Ğ¾Ğ½ Ğ´ĞµÑÑÑ‚ÑŒ ĞºÑ Ğ·Ğ° Ñ‡ĞµÑ‚Ñ‹Ñ€Ğµ Ğ´ĞµĞ²ÑÑ‚ÑŒ Ğ´ĞµĞ²ÑÑ‚ÑŒ Ğ½Ğ¾Ğ»ÑŒ Ñ€ÑƒĞ±Ğ»ĞµĞ¹ Ğ±ĞµĞ· Ñ‚Ñ€ĞµÑ‚ÑŒĞ¸ Ñ‡Ğ°ÑĞ¾Ğ² Ğ¿Ğ¾Ğ»Ğ´ĞµĞ½ÑŒ Ğ¸ Ñ‚.Ğ´.`
> * [text-normalization-ru-terrible](https://huggingface.co/maximxls/text-normalization-ru-terrible) is `Ñ ĞºÑƒĞ¿Ğ¸Ğ» Ğ°Ğ¹Ñ„Ğ¾Ğ½ ÑÑ‚Ğ¾ Ğ¸ĞºÑ Ğ·Ğ° Ñ‚Ñ‹ÑÑÑ‡Ñƒ Ñ‡ĞµÑ‚Ñ‹Ñ€ĞµÑÑ‚Ğ° Ğ´ĞµĞ²ÑĞ½Ğ¾ÑÑ‚Ğ¾ Ñ€ÑƒĞ±Ğ»Ğµ Ğ±ĞµĞ· Ñ‚Ñ€ĞµÑ‚ÑŒĞ¸Ñ… Ñ‡Ğ°ÑĞ¾Ğ² Ğ¿Ğ¾Ğ»`,
> * [text-normalization-ru-new](https://huggingface.co/alexue4/text-normalization-ru-new) is `Ñ ĞºÑƒĞ¿Ğ¸Ğ» Ğ¸Ñ„Ğ¾Ğ½ Ğ´ĞµÑÑÑ‚ÑŒ Ğ¸ĞºÑ Ğ·Ğ° Ñ‡ĞµÑ‚Ñ‹Ñ€Ğ½Ğ°Ğ´Ñ†Ğ°Ñ‚ÑŒ Ñ‚Ñ‹ÑÑÑ‡ Ğ´ĞµĞ²ÑÑ‚ÑŒ`.

### The plan

I went along with! Took these steps:

1. Get a dataset.
    > Done with notebooks to [find](./work/dataset/1_find_numbers.ipynb) and to [itn](./work/dataset/2_inverse_normalize.ipynb) texts, then to [construct dataset](./work/dataset/3_process_itn.ipynb).
    1. Download any vast (informal?) russian raw text corpus. Could be
        * [IlyaGusev/ficbook](https://huggingface.co/datasets/IlyaGusev/ficbook),
        * [IlyaGusev/librusec_full](https://huggingface.co/datasets/IlyaGusev/librusec_full), or
        * ~~[Taiga Corpus](https://tatianashavrina.github.io/taiga_site)~~ [pikabu](https://huggingface.co/datasets/IlyaGusev/pikabu)!
    1. Find occurances w/ regexp patterns like `r"Ğ´Ğ²Ğ°Ğ´Ñ†Ğ°Ñ‚\S+"`, 
    1. Make sure there is nothing but cyrillic.
    1. Make inverse text normalization (that task is more straightforward and many good solutions do exist).
        * Used ~~[NeMo Text Processing](https://github.com/NVIDIA/NeMo-text-processing)~~ [another python package](https://github.com/flockentanz/word_to_number_ru) with some additions.
    1. Polish things roughly like balance (as `Ğ´Ğ²Ğ°` seems to be *far* more common than `Ğ´Ğ²ÑƒĞ¼ÑÑÑ‚Ğ°Ğ¼Ğ¸`), get rid of ITN mistakes etc.
1. Train an MVP.
    > Done with notebooks to [train](./work/train/train.ipynb) and to [distributed train](./work/train/train-distributed.ipynb) a model.
    1. Get a relatively big LLM as we are going to prune it then (and to onnx it as well so that the resulting performance is compatible with the solution I've mantioned).
        * Seems to be [ai-forever/FRED-T5-1.7B](https://huggingface.co/ai-forever/FRED-T5-1.7B) as it is encoder-decoder, trainable on single **RTX3060 12GB** and good enough to get an MVP.
            > Turned out that 12GB is enough to inference it only so I've trained [ai-forever/FRED-T5-large](https://huggingface.co/ai-forever/FRED-T5-large).

            > I've managed to run **FRED-T5-1.7B** train on two 12GB GPUs using [`tensor_parallel`](https://github.com/BlackSamorez/tensor_parallel) package but model did not perform notably better. Also, the point is to have a small and fast model to infer it on CPU.
    1. Train, like, any barely working model.
        * Several attempts are required as it is not clear which prompt is better. May be
            ```
            <SC1>Ğ‘Ñ‹Ğ»Ğ¾ Ñƒ Ğ¾Ñ‚Ñ†Ğ° [3]<extra_id_0> ÑÑ‹Ğ½Ğ° Ğ¸ [2-3]<extra_id_1> Ğ¿Ğ¸Ğ´Ğ¶Ğ°ĞºĞ° Ñ Ğ±Ğ»Ñ‘ÑÑ‚ĞºĞ°Ğ¼Ğ¸.
            ```
            > Turned out the pattern below works well so I've made no experiments here.
    1. Test and analyze.
    1. ~~Regret deeply.~~
1. To obtain a dataset of a better quality, we want to ask really big smart ass LLM to **(not inverse!)** normalize texts during the training.
    * Unfortunately, LLM exeriments failed. I took instruct models ([Mistral-7B-Instruct-v0.2](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2), [ruGPT-3.5 13B LoRA](https://huggingface.co/evilfreelancer/ruGPT-3.5-13B-lora), [GigaSaiga](https://huggingface.co/IlyaGusev/gigasaiga_lora), [Saiga2 7B](https://huggingface.co/IlyaGusev/saiga2_13b_lora)) and plain generation ones ([ruGPT-3.5-13B-GPTQ](https://huggingface.co/fffrrt/ruGPT-3.5-13B-GPTQ) and [Vikhr-7b-0.1](https://huggingface.co/AlexWortega/Vikhr-7b-0.1)), but there were always too much of mistakes which can not be catch automatically. Well, they _were_, so I decided to...
1. Take the [Kaggle Text Normalization Challenge](https://www.kaggle.com/competitions/text-normalization-challenge-russian-language) dataset! So I had latin normalization as well.
    > Done with a notebook to [process kaggle data](./work/dataset/4_process_kaggle.ipynb).
1. Train everything again at last. Put [on hf](https://huggingface.co/saarus72/russian_text_normalizer).

## Inverse Text Normalization

There are but a few packages from namely 
* NVidia's [NeMo](https://github.com/NVIDIA/NeMo-text-processing),
* [Oknolaz](https://github.com/Oknolaz/Russian_w2n),
* [SergeyShk](https://github.com/SergeyShk/Word-to-Number-Russian) and its forks from
    * [averkij](https://github.com/averkij/Word-to-Number-Russian) and
    * [flockentanz](https://github.com/flockentanz/word_to_number_ru).

**NeMo** works well but tends to miss many cases I won't have missed (see the comparison table below). I used it as the first attempt but did my research then.

**Oknolaz** needs to be fed with extracted numbers only and does many mistakes in that case even so bad choice for us.

**SergeyShk** does either
* `replace_groups` â€” `Ñ‚Ñ‹ÑÑÑ‡Ğ° ÑÑ‚Ğ¾` to `1100` but `ÑÑ‚Ğ¾ Ğ´Ğ²ĞµÑÑ‚Ğ¸ Ñ‚Ñ€Ğ¸ÑÑ‚Ğ°` to `400` or
* `replace` â€” `ÑÑ‚Ğ¾ Ğ´Ğ²ĞµÑÑ‚Ğ¸ Ñ‚Ñ€Ğ¸ÑÑ‚Ğ°` to `100 200 300` but `Ñ‚Ñ‹ÑÑÑ‡Ğ° ÑÑ‚Ğ¾` to `1000 100`.

It is obvious that addition should be done on decreasing values only so there are some forks to fix it (the overall code is a mess so that I didn't want to do it myself anyway).

**averkij** and **flockentanz** work fine both but have some bugs so I took the second one and fixed them. Also I cover cases like `Ñ Ğ¿Ğ¾Ğ»Ğ¾Ğ²Ğ¸Ğ½Ğ¾Ğ¹` and `Ğ¾Ğ´Ğ½Ğ° Ñ†ĞµĞ»Ğ°Ñ Ğ´Ğ²Ğµ Ğ´ĞµÑÑÑ‚Ñ‹Ñ…`.

| Original | ğŸŸ¡ NeMo TP | ğŸ”´ Oknolaz `replace` | ğŸ”´ SergeyShk `replace_groups` | ğŸ”´ SergeyShk `replace` | ğŸ”´ averkij `replace` | ğŸ”´ flockentanz `replace_groups_sa` | ğŸŸ¢ flockentanz fixed |
|--|--|--|--|--|--|--|--|
| `ÑÑ‚Ğ¾ Ğ´Ğ²ĞµÑÑ‚Ğ¸ Ñ‚Ñ€Ğ¸ÑÑ‚Ğ° Ğ´Ğ° Ñ…Ğ¾Ñ‚ÑŒ Ñ‚Ñ‹ÑÑÑ‡Ñƒ Ñ€Ğ°Ğ·` | ğŸŸ¢`100 200 300 Ğ´Ğ° Ñ…Ğ¾Ñ‚ÑŒ 1000 Ñ€Ğ°Ğ·` | ğŸ”´`600000` | ğŸ”´`400 Ğ´Ğ° Ñ…Ğ¾Ñ‚ÑŒ 1000 Ñ€Ğ°Ğ·` | ğŸŸ¢`100 200 300 Ğ´Ğ° Ñ…Ğ¾Ñ‚ÑŒ 1000 Ñ€Ğ°Ğ·` | ğŸ”´`10200 300 Ğ´Ğ° Ñ…Ğ¾Ñ‚ÑŒ 1000 Ñ€Ğ°Ğ·` | ğŸŸ¢`100 200 300 Ğ´Ğ° Ñ…Ğ¾Ñ‚ÑŒ 1000 Ñ€Ğ°Ğ·` | ğŸŸ¢`100 200 300 Ğ´Ğ° Ñ…Ğ¾Ñ‚ÑŒ 1000 Ñ€Ğ°Ğ·` |
| `Ñ‚Ñ‹ÑÑÑ‡Ğ° ÑÑ‚Ğ¾` | ğŸŸ¢`1100` | ğŸŸ¢`1100` | ğŸŸ¢`1100` | ğŸ”´`1000 100` | ğŸŸ¢`1100` | ğŸŸ¢`1100` | ğŸŸ¢`1100` |
| `Ñ Ğ²Ğ¸Ğ´ĞµĞ» ÑÑ‚Ğ¾-Ğ´Ğ²ĞµÑÑ‚Ğ¸ ÑˆÑ‚ÑƒĞº` | ğŸŸ¡`Ñ Ğ²Ğ¸Ğ´ĞµĞ» ÑÑ‚Ğ¾-Ğ´Ğ²ĞµÑÑ‚Ğ¸ ÑˆÑ‚ÑƒĞº` | ğŸ”´`300` | ğŸŸ¢`Ñ Ğ²Ğ¸Ğ´ĞµĞ» 100-200 ÑˆÑ‚ÑƒĞº` | ğŸŸ¢`Ñ Ğ²Ğ¸Ğ´ĞµĞ» 100-200 ÑˆÑ‚ÑƒĞº` | ğŸŸ¢`Ñ Ğ²Ğ¸Ğ´ĞµĞ» 100-200 ÑˆÑ‚ÑƒĞº` | ğŸŸ¢`Ñ Ğ²Ğ¸Ğ´ĞµĞ» 100-200 ÑˆÑ‚ÑƒĞº` | ğŸŸ¢`Ñ Ğ²Ğ¸Ğ´ĞµĞ» 100-200 ÑˆÑ‚ÑƒĞº` |
| `Ğ²Ğ¾ÑĞµĞ¼ÑŒ Ğ´ĞµĞ²ÑÑ‚ÑŒÑĞ¾Ñ‚ Ğ´Ğ²Ğ°Ğ´Ñ†Ğ°Ñ‚ÑŒ Ğ´Ğ²Ğ° Ğ¿ÑÑ‚ÑŒ Ğ¿ÑÑ‚ÑŒ Ğ¿ÑÑ‚ÑŒ Ñ‚Ñ€Ğ¸Ğ´Ñ†Ğ°Ñ‚ÑŒ Ğ¿ÑÑ‚ÑŒ Ñ‚Ñ€Ğ¸Ğ´Ñ†Ğ°Ñ‚ÑŒ Ğ¿ÑÑ‚ÑŒ, Ğ»ÑƒÑ‡ÑˆĞµ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ½Ğ¸Ñ‚ÑŒ, Ñ‡ĞµĞ¼ Ğ·Ğ°Ğ½Ğ¸Ğ¼Ğ°Ñ‚ÑŒ` | ğŸŸ¡`Ğ²Ğ¾ÑĞµĞ¼ÑŒ 922 Ğ¿ÑÑ‚ÑŒ Ğ¿ÑÑ‚ÑŒ Ğ¿ÑÑ‚ÑŒ 35 35 , Ğ»ÑƒÑ‡ÑˆĞµ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ½Ğ¸Ñ‚ÑŒ, Ñ‡ĞµĞ¼ Ğ·Ğ°Ğ½Ğ¸Ğ¼Ğ°Ñ‚ÑŒ` | ğŸ”´`8` | ğŸ”´`115, Ğ»ÑƒÑ‡ÑˆĞµ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ½Ğ¸Ñ‚ÑŒ, Ñ‡ĞµĞ¼ Ğ·Ğ°Ğ½Ğ¸Ğ¼Ğ°Ñ‚ÑŒ` | ğŸ”´`8 900 20 2 5 5 5 30 5 30 5, Ğ»ÑƒÑ‡ÑˆĞµ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ½Ğ¸Ñ‚ÑŒ, Ñ‡ĞµĞ¼ Ğ·Ğ°Ğ½Ğ¸Ğ¼Ğ°Ñ‚ÑŒ` | ğŸŸ¢`8 922 5 5 5 35 35, Ğ»ÑƒÑ‡ÑˆĞµ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ½Ğ¸Ñ‚ÑŒ, Ñ‡ĞµĞ¼ Ğ·Ğ°Ğ½Ğ¸Ğ¼Ğ°Ñ‚ÑŒ` | ğŸŸ¢`8 922 5 5 5 35 35, Ğ»ÑƒÑ‡ÑˆĞµ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ½Ğ¸Ñ‚ÑŒ, Ñ‡ĞµĞ¼ Ğ·Ğ°Ğ½Ğ¸Ğ¼Ğ°Ñ‚ÑŒ` | ğŸŸ¢`8 922 5 5 5 35 35, Ğ»ÑƒÑ‡ÑˆĞµ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ½Ğ¸Ñ‚ÑŒ, Ñ‡ĞµĞ¼ Ğ·Ğ°Ğ½Ğ¸Ğ¼Ğ°Ñ‚ÑŒ` |
| `Ñ‚Ñ€Ğ¸ Ñ Ğ¿Ğ¾Ğ»Ğ¾Ğ²Ğ¸Ğ½Ğ¾Ğ¹ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞºĞ°` | ğŸŸ¡`Ñ‚Ñ€Ğ¸ Ñ Ğ¿Ğ¾Ğ»Ğ¾Ğ²Ğ¸Ğ½Ğ¾Ğ¹ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞºĞ°` | ğŸ”´`3` | ğŸŸ¡`3 Ñ Ğ¿Ğ¾Ğ»Ğ¾Ğ²Ğ¸Ğ½Ğ¾Ğ¹ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞºĞ°` | ğŸŸ¡`3 Ñ Ğ¿Ğ¾Ğ»Ğ¾Ğ²Ğ¸Ğ½Ğ¾Ğ¹ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞºĞ°` | ğŸŸ¢`3.5 Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞºĞ°` | ğŸŸ¡`3 Ñ Ğ¿Ğ¾Ğ»Ğ¾Ğ²Ğ¸Ğ½Ğ¾Ğ¹ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞºĞ°` | ğŸŸ¢`3.5 Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞºĞ°` |
| `Ğ¼Ğ¸Ğ»Ğ»Ğ¸Ğ¾Ğ½ ÑÑ‚Ğ¾ Ñ‚Ñ‹ÑÑÑ‡ ÑÑ‚Ğ¾ Ğ·Ğ°Ğ¹Ñ†ĞµĞ²` | ğŸŸ¢`1100100 Ğ·Ğ°Ğ¹Ñ†ĞµĞ²` | âŒ`list index out of range` | ğŸ”´`1000100100 Ğ·Ğ°Ğ¹Ñ†ĞµĞ²` | ğŸ”´`1000000 100000 100 Ğ·Ğ°Ğ¹Ñ†ĞµĞ²` | `1100100 Ğ·Ğ°Ğ¹Ñ†ĞµĞ²` | ğŸ”´`1000100100 Ğ·Ğ°Ğ¹Ñ†ĞµĞ²` | ğŸŸ¢`1100100 Ğ·Ğ°Ğ¹Ñ†ĞµĞ²` |
| `Ğ¾Ğ´Ğ½Ğ¸ Ğ´Ğ²Ğ¾Ğ¹ĞºĞ¸ Ğ¸ Ğ½Ğ¸ Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ğ¿ÑÑ‚Ñ‘Ñ€ĞºĞ¸` | ğŸŸ¡`Ğ¾Ğ´Ğ½Ğ¸ Ğ´Ğ²Ğ¾Ğ¹ĞºĞ¸ Ğ¸ Ğ½Ğ¸ Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ğ¿ÑÑ‚Ñ‘Ñ€ĞºĞ¸` | ğŸŸ¡`No valid number words found! ...` | ğŸŸ¡`1 Ğ´Ğ²Ğ¾Ğ¹ĞºĞ¸ Ğ¸ Ğ½Ğ¸ 1 Ğ¿ÑÑ‚Ñ‘Ñ€ĞºĞ¸` | ğŸŸ¡`1 Ğ´Ğ²Ğ¾Ğ¹ĞºĞ¸ Ğ¸ Ğ½Ğ¸ 1 Ğ¿ÑÑ‚Ñ‘Ñ€ĞºĞ¸` | ğŸŸ¡`1 Ğ´Ğ²Ğ¾Ğ¹ĞºĞ¸ Ğ¸ Ğ½Ğ¸ 1 Ğ¿ÑÑ‚Ñ‘Ñ€ĞºĞ¸` | ğŸŸ¡`1 Ğ´Ğ²Ğ¾Ğ¹ĞºĞ¸ Ğ¸ Ğ½Ğ¸ 1 Ğ¿ÑÑ‚Ñ‘Ñ€ĞºĞ¸` | ğŸŸ¡`1 Ğ´Ğ²Ğ¾Ğ¹ĞºĞ¸ Ğ¸ Ğ½Ğ¸ 1 Ğ¿ÑÑ‚Ñ‘Ñ€ĞºĞ¸` |
| `Ğ±ĞµĞ· Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñ‹ Ğ´Ğ²Ğ°` |ğŸŸ¢ `01:59` | ğŸ”´`2` | ğŸŸ¢`Ğ±ĞµĞ· 1 Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñ‹ 2` | ğŸŸ¢`Ğ±ĞµĞ· 1 Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñ‹ 2` | ğŸŸ¢`Ğ±ĞµĞ· 1 Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñ‹ 2` | ğŸŸ¢`Ğ±ĞµĞ· 1 Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñ‹ 2` | ğŸŸ¢`Ğ±ĞµĞ· 1 Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñ‹ 2` |
| `Ğ²Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ´Ğ°Ñ‡Ğ° Ğ¿ÑÑ‚ÑŒ ÑĞ¾Ñ‚Ğ¾Ğº` | ğŸŸ¡`Ğ²Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ´Ğ°Ñ‡Ğ° Ğ¿ÑÑ‚ÑŒ ÑĞ¾Ñ‚Ğ¾Ğº` | ğŸ”´`5` | ğŸŸ¢`2 Ğ´Ğ°Ñ‡Ğ° 5 ÑĞ¾Ñ‚Ğ¾Ğº` | ğŸŸ¢`2 Ğ´Ğ°Ñ‡Ğ° 5 ÑĞ¾Ñ‚Ğ¾Ğº` | ğŸŸ¢`2 Ğ´Ğ°Ñ‡Ğ° 5 ÑĞ¾Ñ‚Ğ¾Ğº` | ğŸŸ¢`2 Ğ´Ğ°Ñ‡Ğ° 5 ÑĞ¾Ñ‚Ğ¾Ğº` | ğŸŸ¢`2 Ğ´Ğ°Ñ‡Ğ° 5 ÑĞ¾Ñ‚Ğ¾Ğº` |
| `Ğ´Ğ²ĞµÑÑ‚Ğ¸ Ğ¿ÑÑ‚ÑŒĞ´ĞµÑÑÑ‚ Ñ Ğ¿Ğ¾Ğ»Ğ¾Ğ²Ğ¸Ğ½Ğ¾Ğ¹ Ñ‚Ñ‹ÑÑÑ‡ Ğ¾Ñ‚Ğ±Ğ¾Ñ€Ğ½Ñ‹Ñ… ÑĞ¾Ğ»Ğ´Ğ°Ñ‚ Ğ˜Ñ€Ğ°ĞºĞ°` | ğŸŸ¡`250 Ñ Ğ¿Ğ¾Ğ»Ğ¾Ğ²Ğ¸Ğ½Ğ¾Ğ¹ 1000 Ğ¾Ñ‚Ğ±Ğ¾Ñ€Ğ½Ñ‹Ñ… ÑĞ¾Ğ»Ğ´Ğ°Ñ‚ Ğ˜Ñ€Ğ°ĞºĞ°` | ğŸ”´`250000` | ğŸŸ¡`250 Ñ Ğ¿Ğ¾Ğ»Ğ¾Ğ²Ğ¸Ğ½Ğ¾Ğ¹ 1000 Ğ¾Ñ‚Ğ±Ğ¾Ñ€Ğ½Ñ‹Ñ… ÑĞ¾Ğ»Ğ´Ğ°Ñ‚ Ğ˜Ñ€Ğ°ĞºĞ°` | ğŸ”´`200 50 Ñ Ğ¿Ğ¾Ğ»Ğ¾Ğ²Ğ¸Ğ½Ğ¾Ğ¹ 1000 Ğ¾Ñ‚Ğ±Ğ¾Ñ€Ğ½Ñ‹Ñ… ÑĞ¾Ğ»Ğ´Ğ°Ñ‚ Ğ˜Ñ€Ğ°ĞºĞ°` | ğŸ”´`2050000.5 Ğ¾Ñ‚Ğ±Ğ¾Ñ€Ğ½Ñ‹Ñ… ÑĞ¾Ğ»Ğ´Ğ°Ñ‚ Ğ˜Ñ€Ğ°ĞºĞ°` | ğŸŸ¡`250 Ñ Ğ¿Ğ¾Ğ»Ğ¾Ğ²Ğ¸Ğ½Ğ¾Ğ¹ 1000 Ğ¾Ñ‚Ğ±Ğ¾Ñ€Ğ½Ñ‹Ñ… ÑĞ¾Ğ»Ğ´Ğ°Ñ‚ Ğ˜Ñ€Ğ°ĞºĞ°` | ğŸŸ¢`250500 Ğ¾Ñ‚Ğ±Ğ¾Ñ€Ğ½Ñ‹Ñ… ÑĞ¾Ğ»Ğ´Ğ°Ñ‚ Ğ˜Ñ€Ğ°ĞºĞ°` |
| `Ğ½Ğ¾Ğ»ÑŒ Ñ†ĞµĞ»Ñ‹Ñ… Ğ½Ğ¾Ğ»ÑŒ Ğ´ĞµÑÑÑ‚Ñ‹Ñ… Ğ¼Ğ¸Ğ½ÑƒÑ Ğ´Ğ²Ğµ Ñ†ĞµĞ»Ñ‹Ñ… ÑˆĞµÑÑ‚ÑŒ ÑĞ¾Ñ‚Ñ‹Ñ…` | ğŸŸ¢`0,0 -2,06` | ğŸŸ¡`Redundant number word! ...` | ğŸ”´`0 Ñ†ĞµĞ»Ñ‹Ñ… 0.0 Ğ¼Ğ¸Ğ½ÑƒÑ 2 Ñ†ĞµĞ»Ñ‹Ñ… 0.06` | ğŸ”´`0 Ñ†ĞµĞ»Ñ‹Ñ… 0.0 Ğ¼Ğ¸Ğ½ÑƒÑ 2 Ñ†ĞµĞ»Ñ‹Ñ… 0.06` | ğŸ”´`0 Ñ†ĞµĞ»Ñ‹Ñ… 0.0 Ğ¼Ğ¸Ğ½ÑƒÑ 2 Ñ†ĞµĞ»Ñ‹Ñ… 0.06` | ğŸ”´`0 Ñ†ĞµĞ»Ñ‹Ñ… 0.0 Ğ¼Ğ¸Ğ½ÑƒÑ 2 Ñ†ĞµĞ»Ñ‹Ñ… 0.06` | ğŸŸ¢`0 Ğ¼Ğ¸Ğ½ÑƒÑ 2.06` |